{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Deep Fakes - Training Pipeline\n",
    "\n",
    "This notebook trains a **Graph VAE + Latent Diffusion** model to generate synthetic FEA signals on a mesh.\n",
    "\n",
    "## Architecture\n",
    "1. **Graph Autoencoder**: Compresses 6523-dim field to ~64-dim latent using spectral projection\n",
    "2. **Graph-Aware Diffusion (GAD)**: DDPM-style diffusion on the latent space with polynomial graph filters\n",
    "3. **Generation**: Sample latent codes from diffusion → decode to mesh field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.tri import Triangulation\n",
    "from scipy.sparse import csr_matrix, diags, linalg as splinalg, save_npz, load_npz\n",
    "from scipy.spatial import Delaunay\n",
    "import time\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "# Check for PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "print(f\"PyTorch {torch.__version__}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dataset generation\nDATASET_DIR = \"dataset\"\nMESH_RESOLUTION = 0.005\n\n# Parameter ranges\nDIFFUSIVITY_VALUES = [0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0]\nSOURCE_VALUES = [0.5, 1.0, 2.0, 3.0, 4.0, 5.0, 7.0]\n# Cylinder fixed at y=0 (mesh geometry must match BC location)\n\n# Domain\nCYLINDER_RADIUS = 0.05\nDOMAIN_RADIUS = 0.15\nX_MIN, X_MAX = -DOMAIN_RADIUS, DOMAIN_RADIUS * 2.5\nY_MIN, Y_MAX = -DOMAIN_RADIUS, DOMAIN_RADIUS\n\n# Model architecture\nLATENT_DIM = 64\nHIDDEN_DIM = 256\nN_ENCODER_LAYERS = 4\nN_DECODER_LAYERS = 4\n\n# Diffusion\nDIFFUSION_STEPS = 100\nBETA_START = 1e-4\nBETA_END = 0.02\n\n# Training\nBATCH_SIZE = 64\nLEARNING_RATE = 1e-3\nAE_EPOCHS = 500\nDIFF_EPOCHS = 800\n\nOUTPUT_DIR = \"training_output\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nos.makedirs(DATASET_DIR, exist_ok=True)\n\nn_total_samples = len(DIFFUSIVITY_VALUES) * len(SOURCE_VALUES)\nprint(f\"Will generate {n_total_samples} FEA solutions\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mesh(x_min, x_max, y_min, y_max, cx, cy, r, resolution):\n",
    "    \"\"\"Generate 2D triangular mesh for rectangular domain with circular obstacle.\"\"\"\n",
    "    nx = int((x_max - x_min) / resolution) + 1\n",
    "    ny = int((y_max - y_min) / resolution) + 1\n",
    "\n",
    "    x = np.linspace(x_min, x_max, nx)\n",
    "    y = np.linspace(y_min, y_max, ny)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    points = np.column_stack([xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Remove points inside cylinder\n",
    "    dist_to_center = np.sqrt((points[:, 0] - cx)**2 + (points[:, 1] - cy)**2)\n",
    "    outside_cylinder = dist_to_center > r * 1.1\n",
    "    points = points[outside_cylinder]\n",
    "\n",
    "    # Add rings around cylinder\n",
    "    for ring_factor in [1.0, 1.15, 1.3]:\n",
    "        n_circle = int(2 * np.pi * r * ring_factor / (resolution * 0.5))\n",
    "        theta = np.linspace(0, 2*np.pi, n_circle, endpoint=False)\n",
    "        circle_points = np.column_stack([\n",
    "            cx + r * ring_factor * np.cos(theta),\n",
    "            cy + r * ring_factor * np.sin(theta)\n",
    "        ])\n",
    "        points = np.vstack([points, circle_points])\n",
    "\n",
    "    tri = Delaunay(points)\n",
    "    triangles = tri.simplices\n",
    "\n",
    "    # Remove triangles inside cylinder\n",
    "    centroids = points[triangles].mean(axis=1)\n",
    "    dist_centroids = np.sqrt((centroids[:, 0] - cx)**2 + (centroids[:, 1] - cy)**2)\n",
    "    valid_triangles = triangles[dist_centroids > r]\n",
    "\n",
    "    return points, valid_triangles\n",
    "\n",
    "print(\"Generating mesh...\")\n",
    "start = time.time()\n",
    "points, triangles = generate_mesh(\n",
    "    X_MIN, X_MAX, Y_MIN, Y_MAX,\n",
    "    0.0, 0.0, CYLINDER_RADIUS, MESH_RESOLUTION\n",
    ")\n",
    "n_nodes = len(points)\n",
    "n_elements = len(triangles)\n",
    "print(f\"Mesh: {n_nodes} nodes, {n_elements} elements ({time.time()-start:.2f}s)\")\n",
    "\n",
    "# Visualize mesh\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.triplot(points[:, 0], points[:, 1], triangles, linewidth=0.2, color='blue')\n",
    "circle = plt.Circle((0, 0), CYLINDER_RADIUS, fill=True, color='cyan', ec='black')\n",
    "ax.add_patch(circle)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title(f'Mesh: {n_nodes} nodes, {n_elements} triangles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Graph Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cotangent_laplacian(points, triangles):\n",
    "    \"\"\"Build cotangent-weighted Laplacian matrix.\"\"\"\n",
    "    n = len(points)\n",
    "    rows, cols, weights = [], [], []\n",
    "\n",
    "    for tri in triangles:\n",
    "        p = points[tri]\n",
    "        for i in range(3):\n",
    "            j = (i + 1) % 3\n",
    "            k = (i + 2) % 3\n",
    "            vi, vj, vk = tri[i], tri[j], tri[k]\n",
    "\n",
    "            e1 = p[i] - p[k]\n",
    "            e2 = p[j] - p[k]\n",
    "\n",
    "            cos_angle = np.dot(e1, e2)\n",
    "            e1_3d = np.array([e1[0], e1[1], 0])\n",
    "            e2_3d = np.array([e2[0], e2[1], 0])\n",
    "            sin_angle = np.abs(np.linalg.norm(np.cross(e1_3d, e2_3d)))\n",
    "            cot_weight = cos_angle / (sin_angle + 1e-10) * 0.5\n",
    "            cot_weight = max(cot_weight, 0)\n",
    "\n",
    "            rows.extend([vi, vj])\n",
    "            cols.extend([vj, vi])\n",
    "            weights.extend([cot_weight, cot_weight])\n",
    "\n",
    "    W = csr_matrix((weights, (rows, cols)), shape=(n, n))\n",
    "    W = W.tocsr()\n",
    "    D = diags(np.array(W.sum(axis=1)).flatten())\n",
    "    L = D - W\n",
    "    return L, W\n",
    "\n",
    "print(\"Building Laplacian...\")\n",
    "start = time.time()\n",
    "L, W = build_cotangent_laplacian(points, triangles)\n",
    "print(f\"Laplacian: {L.shape}, nnz={L.nnz} ({time.time()-start:.2f}s)\")\n",
    "\n",
    "# Compute eigendecomposition\n",
    "print(\"Computing eigenvectors...\")\n",
    "start = time.time()\n",
    "n_eigs = 50\n",
    "L_reg = L + 1e-8 * diags(np.ones(n_nodes))\n",
    "eigenvalues, eigenvectors = splinalg.eigsh(\n",
    "    L_reg, k=n_eigs, which='LM', sigma=1e-6, tol=1e-4, maxiter=5000\n",
    ")\n",
    "eigenvalues = np.real(eigenvalues)\n",
    "eigenvectors = np.real(eigenvectors)\n",
    "idx = np.argsort(eigenvalues)\n",
    "eigenvalues = eigenvalues[idx]\n",
    "eigenvectors = eigenvectors[:, idx]\n",
    "print(f\"Computed {n_eigs} eigenvectors ({time.time()-start:.2f}s)\")\n",
    "\n",
    "# Plot first few eigenvectors\n",
    "triang = Triangulation(points[:, 0], points[:, 1], triangles)\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 6))\n",
    "fig.suptitle('First 8 Laplacian Eigenvectors (Manifold Harmonics)', fontweight='bold')\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.tripcolor(triang, eigenvectors[:, i], cmap='RdBu', shading='gouraud')\n",
    "    circle = plt.Circle((0, 0), CYLINDER_RADIUS, fill=True, color='gray', ec='black')\n",
    "    ax.add_patch(circle)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'Mode {i}: λ={eigenvalues[i]:.4f}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate FEA Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def solve_heat_equation(points, L, diffusivity, source_strength):\n    \"\"\"Solve steady heat equation with parameter-dependent source and BCs.\"\"\"\n    n = len(points)\n    x, y = points[:, 0], points[:, 1]\n    cx, cy = 0.0, 0.0  # Cylinder fixed at origin (matches mesh geometry)\n    r = CYLINDER_RADIUS\n    \n    dist = np.sqrt((x - cx)**2 + (y - cy)**2)\n    \n    # Source term\n    source = np.zeros(n)\n    source_region = dist < r * 3\n    source[source_region] = source_strength * np.exp(-(dist[source_region] - r)**2 / (r**2))\n    source += source_strength * 0.3 * np.sin(np.pi * y / Y_MAX) * (x > 0)\n    \n    # System matrix\n    A = diffusivity * L + 1e-6 * diags(np.ones(n))\n    b = source.copy()\n    \n    # Boundary conditions\n    tol = MESH_RESOLUTION * 1.5\n    left = x < X_MIN + tol\n    right = x > X_MAX - tol\n    top = y > Y_MAX - tol\n    bottom = y < Y_MIN + tol\n    on_cylinder = dist < r * 1.3\n    \n    bc_nodes = left | right | top | bottom | on_cylinder\n    u_bc = np.zeros(n)\n    u_bc[left] = 1.0\n    u_bc[right] = 0.0\n    u_bc[top] = 0.5 + 0.3 * source_strength / 5\n    u_bc[bottom] = 0.5 - 0.3 * source_strength / 5\n    u_bc[on_cylinder] = 0.2 + 0.6 * diffusivity\n    \n    A_mod = A.tolil()\n    for i in np.where(bc_nodes)[0]:\n        A_mod[i, :] = 0\n        A_mod[i, i] = 1.0\n        b[i] = u_bc[i]\n    A_mod = A_mod.tocsr()\n    \n    u = splinalg.spsolve(A_mod, b)\n    u = np.nan_to_num(u, nan=0.5, posinf=1.0, neginf=0.0)\n    \n    u_min, u_max = u.min(), u.max()\n    if u_max > u_min:\n        u = (u - u_min) / (u_max - u_min)\n    \n    return u"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate all solutions\nparam_combinations = list(product(DIFFUSIVITY_VALUES, SOURCE_VALUES))\nn_samples = len(param_combinations)\n\nprint(f\"Generating {n_samples} FEA solutions...\")\nsolutions = np.zeros((n_samples, n_nodes))\nparameters = np.zeros((n_samples, 2))  # [diffusivity, source]\n\nstart_time = time.time()\nfor idx, (diffusivity, source) in enumerate(param_combinations):\n    u = solve_heat_equation(points, L, diffusivity, source)\n    solutions[idx] = u\n    parameters[idx] = [diffusivity, source]\n    \n    if (idx + 1) % 10 == 0 or idx == 0:\n        elapsed = time.time() - start_time\n        rate = (idx + 1) / elapsed\n        remaining = (n_samples - idx - 1) / rate\n        print(f\"  [{idx+1:3d}/{n_samples}] {elapsed:.1f}s elapsed, ~{remaining:.1f}s remaining\")\n\nprint(f\"\\nCompleted {n_samples} solutions in {time.time()-start_time:.1f}s\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize sample solutions\nfig, axes = plt.subplots(3, 3, figsize=(14, 11))\nfig.suptitle(f'Sample FEA Solutions ({n_samples} total)', fontsize=14, fontweight='bold')\n\nsample_indices = [0, n_samples//4, n_samples//2, 3*n_samples//4, n_samples-1,\n                  n_samples//8, 3*n_samples//8, 5*n_samples//8, 7*n_samples//8]\n\nfor ax, idx in zip(axes.flatten(), sample_indices):\n    diff, src = parameters[idx]\n    sol = solutions[idx]\n    levels = np.linspace(0, 1, 30)\n    tcf = ax.tricontourf(triang, sol, levels=levels, cmap='inferno', extend='both')\n    ax.tricontour(triang, sol, levels=10, colors='white', linewidths=0.3, alpha=0.5)\n    circle = plt.Circle((0, 0), CYLINDER_RADIUS, fill=True, color='cyan', ec='black', lw=1)\n    ax.add_patch(circle)\n    ax.set_aspect('equal')\n    ax.set_title(f'k={diff:.1f}, Q={src:.1f}')\n    ax.axis('off')\n\nfig.subplots_adjust(right=0.92)\ncbar_ax = fig.add_axes([0.94, 0.15, 0.02, 0.7])\nsm = plt.cm.ScalarMappable(cmap='inferno', norm=plt.Normalize(0, 1))\nfig.colorbar(sm, cax=cbar_ax, label='Temperature')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save dataset\nnp.savez(f\"{DATASET_DIR}/mesh.npz\", points=points, triangles=triangles,\n         eigenvalues=eigenvalues, eigenvectors=eigenvectors)\nsave_npz(f\"{DATASET_DIR}/laplacian.npz\", L)\nsave_npz(f\"{DATASET_DIR}/adjacency.npz\", W)\nnp.savez(f\"{DATASET_DIR}/solutions.npz\", solutions=solutions, parameters=parameters,\n         param_names=['diffusivity', 'source'])\n\nprint(f\"Saved dataset to {DATASET_DIR}/\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralGraphEncoder(nn.Module):\n",
    "    def __init__(self, n_nodes, n_eigenvectors, latent_dim, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "        self.spectral_proj = nn.Linear(n_eigenvectors, hidden_dim)\n",
    "        self.spatial_proj = nn.Linear(n_nodes, hidden_dim)\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            in_dim = hidden_dim * 2 if i == 0 else hidden_dim\n",
    "            layers.extend([nn.Linear(in_dim, hidden_dim), nn.LayerNorm(hidden_dim),\n",
    "                          nn.GELU(), nn.Dropout(0.1)])\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.to_latent_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.to_latent_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x, eigenvectors):\n",
    "        x_spectral = torch.matmul(x, eigenvectors)\n",
    "        h_spectral = self.spectral_proj(x_spectral)\n",
    "        h_spatial = self.spatial_proj(x)\n",
    "        h = torch.cat([h_spectral, h_spatial], dim=-1)\n",
    "        h = self.layers(h)\n",
    "        return self.to_latent_mu(h), self.to_latent_logvar(h)\n",
    "\n",
    "\n",
    "class SpectralGraphDecoder(nn.Module):\n",
    "    def __init__(self, n_nodes, n_eigenvectors, latent_dim, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "        self.from_latent = nn.Linear(latent_dim, hidden_dim)\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.extend([nn.Linear(hidden_dim, hidden_dim), nn.LayerNorm(hidden_dim),\n",
    "                          nn.GELU(), nn.Dropout(0.1)])\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.to_spectral = nn.Linear(hidden_dim, n_eigenvectors)\n",
    "        self.to_spatial_residual = nn.Linear(hidden_dim, n_nodes)\n",
    "\n",
    "    def forward(self, z, eigenvectors):\n",
    "        h = self.from_latent(z)\n",
    "        h = self.layers(h)\n",
    "        spectral_coef = self.to_spectral(h)\n",
    "        x_spectral = torch.matmul(spectral_coef, eigenvectors.T)\n",
    "        x_residual = self.to_spatial_residual(h)\n",
    "        return x_spectral + 0.1 * x_residual\n",
    "\n",
    "\n",
    "class GraphVAE(nn.Module):\n",
    "    def __init__(self, n_nodes, n_eigenvectors, latent_dim, hidden_dim, n_layers):\n",
    "        super().__init__()\n",
    "        self.encoder = SpectralGraphEncoder(n_nodes, n_eigenvectors, latent_dim, hidden_dim, n_layers)\n",
    "        self.decoder = SpectralGraphDecoder(n_nodes, n_eigenvectors, latent_dim, hidden_dim, n_layers)\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        return mu + torch.randn_like(std) * std\n",
    "\n",
    "    def forward(self, x, eigenvectors):\n",
    "        mu, logvar = self.encoder(x, eigenvectors)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z, eigenvectors), mu, logvar, z\n",
    "\n",
    "    def encode(self, x, eigenvectors):\n",
    "        mu, _ = self.encoder(x, eigenvectors)\n",
    "        return mu\n",
    "\n",
    "    def decode(self, z, eigenvectors):\n",
    "        return self.decoder(z, eigenvectors)\n",
    "\n",
    "print(\"GraphVAE defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb_scale = np.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb_scale)\n",
    "        emb = t.float().unsqueeze(-1) * emb.unsqueeze(0)\n",
    "        return torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "\n",
    "\n",
    "class GraphFilterTap(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, filter_order=4):\n",
    "        super().__init__()\n",
    "        self.filter_order = filter_order\n",
    "        self.theta = nn.Parameter(torch.randn(filter_order + 1, in_channels, out_channels) * 0.01)\n",
    "        self.norm = nn.LayerNorm(out_channels)\n",
    "\n",
    "    def forward(self, x, S_powers):\n",
    "        out = torch.zeros(x.shape[0], x.shape[1], self.theta.shape[2], device=x.device)\n",
    "        for k in range(self.filter_order + 1):\n",
    "            Sk_x = torch.matmul(S_powers[k].unsqueeze(0), x)\n",
    "            out = out + torch.einsum('bni,ioj->bno', Sk_x, self.theta[k:k+1].squeeze(0))\n",
    "        return self.norm(F.silu(out))\n",
    "\n",
    "\n",
    "class PolynomialGraphFilterDenoiser(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, filter_order=4, n_layers=3):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.filter_order = filter_order\n",
    "\n",
    "        self.time_embed = nn.Sequential(\n",
    "            SinusoidalPositionalEmbedding(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "        S_init = torch.zeros(latent_dim, latent_dim)\n",
    "        for i in range(latent_dim - 1):\n",
    "            S_init[i, i+1] = 0.5\n",
    "            S_init[i+1, i] = 0.5\n",
    "        S_init = S_init + 0.1 * torch.eye(latent_dim)\n",
    "        self.S = nn.Parameter(S_init)\n",
    "\n",
    "        hidden_channels = 32\n",
    "        self.input_proj = nn.Linear(1 + hidden_dim // latent_dim + 1, hidden_channels)\n",
    "        self.layers = nn.ModuleList([GraphFilterTap(hidden_channels, hidden_channels, filter_order)\n",
    "                                     for _ in range(n_layers)])\n",
    "        self.output_proj = nn.Sequential(nn.Linear(hidden_channels, hidden_channels),\n",
    "                                         nn.SiLU(), nn.Linear(hidden_channels, 1))\n",
    "        self.residual_weight = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "    def _compute_S_powers(self):\n",
    "        S_powers = [torch.eye(self.latent_dim, device=self.S.device)]\n",
    "        S_current = self.S\n",
    "        for k in range(self.filter_order):\n",
    "            S_powers.append(S_current.clone())\n",
    "            S_current = torch.matmul(S_current, self.S)\n",
    "        return S_powers\n",
    "\n",
    "    def forward(self, z, t, n_steps):\n",
    "        batch_size = z.shape[0]\n",
    "        t_norm = t.float() / n_steps\n",
    "        t_embed = self.time_embed(t_norm)\n",
    "        t_per_node = t_embed.unsqueeze(1).expand(-1, self.latent_dim, -1)\n",
    "        t_per_node = t_per_node[..., :self.hidden_dim // self.latent_dim + 1]\n",
    "        \n",
    "        z_expanded = z.unsqueeze(-1)\n",
    "        x = torch.cat([z_expanded, t_per_node], dim=-1)\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        S_powers = self._compute_S_powers()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, S_powers) + x\n",
    "        \n",
    "        out = self.output_proj(x).squeeze(-1)\n",
    "        return out + self.residual_weight * z\n",
    "\n",
    "\n",
    "class GraphAwareDiffusion(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, n_steps, n_eigenvectors):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "        eigenvalues = torch.linspace(0, 2, latent_dim) ** 2\n",
    "        self.register_buffer('eigenvalues', eigenvalues)\n",
    "        self._setup_gasde_schedule(n_steps)\n",
    "        self.denoiser = PolynomialGraphFilterDenoiser(latent_dim, hidden_dim)\n",
    "\n",
    "    def _setup_gasde_schedule(self, n_steps):\n",
    "        c_min, alpha, k = 0.1, 2.0, 2.0\n",
    "        t = torch.linspace(0, 1, n_steps)\n",
    "        c_t = c_min + k * (t ** alpha)\n",
    "        self.register_buffer('c_t', c_t)\n",
    "        s_t = c_min * t + k * (t ** (alpha + 1)) / (alpha + 1)\n",
    "        self.register_buffer('s_t', s_t)\n",
    "\n",
    "        decay = torch.exp(-s_t.unsqueeze(-1) * self.eigenvalues.unsqueeze(0))\n",
    "        self.register_buffer('decay', decay)\n",
    "\n",
    "        eigenvalues_safe = self.eigenvalues.clamp(min=1e-6)\n",
    "        marginal_var = (1 - torch.exp(-2 * s_t.unsqueeze(-1) * eigenvalues_safe.unsqueeze(0))) / (2 * eigenvalues_safe.unsqueeze(0))\n",
    "        self.register_buffer('marginal_std', torch.sqrt(marginal_var.clamp(min=1e-8)))\n",
    "\n",
    "        alphas_cumprod = (decay ** 2).mean(dim=-1).clamp(min=1e-6, max=1.0)\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1.0 - alphas_cumprod))\n",
    "\n",
    "    def forward(self, z_noisy, t):\n",
    "        return self.denoiser(z_noisy, t, self.n_steps)\n",
    "\n",
    "    def add_noise(self, z, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(z)\n",
    "        decay_t = self.decay[t]\n",
    "        std_t = self.marginal_std[t]\n",
    "        return decay_t * z + std_t * noise, noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, n_samples, device):\n",
    "        z = torch.randn(n_samples, self.latent_dim, device=device)\n",
    "        dt = 1.0 / self.n_steps\n",
    "\n",
    "        for t in reversed(range(self.n_steps)):\n",
    "            t_batch = torch.full((n_samples,), t, device=device, dtype=torch.long)\n",
    "            c = self.c_t[t]\n",
    "            noise_pred = self.forward(z, t_batch)\n",
    "\n",
    "            if t > 0:\n",
    "                std_t = self.marginal_std[t].unsqueeze(0)\n",
    "                score_estimate = -noise_pred / (std_t + 1e-6)\n",
    "                drift = c * self.eigenvalues.unsqueeze(0) * z + 2 * c * score_estimate\n",
    "                diffusion = torch.sqrt(2 * c)\n",
    "                z = z - drift * dt + diffusion * np.sqrt(dt) * torch.randn_like(z)\n",
    "            else:\n",
    "                std_t = self.marginal_std[t].unsqueeze(0)\n",
    "                score_estimate = -noise_pred / (std_t + 1e-6)\n",
    "                z = z + 2 * c * score_estimate * dt\n",
    "\n",
    "        return z\n",
    "\n",
    "print(\"GraphAwareDiffusion defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eigenvectors = eigenvectors.shape[1]\n",
    "\n",
    "# Convert to tensors\n",
    "solutions_tensor = torch.FloatTensor(solutions).to(device)\n",
    "parameters_tensor = torch.FloatTensor(parameters).to(device)\n",
    "eigenvectors_tensor = torch.FloatTensor(eigenvectors).to(device)\n",
    "\n",
    "# Create data loader\n",
    "dataset = TensorDataset(solutions_tensor, parameters_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(f\"Solutions: {solutions_tensor.shape}\")\n",
    "print(f\"Eigenvectors: {eigenvectors_tensor.shape}\")\n",
    "print(f\"DataLoader: {len(dataloader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = GraphVAE(n_nodes, n_eigenvectors, LATENT_DIM, HIDDEN_DIM, N_ENCODER_LAYERS).to(device)\n",
    "diffusion = GraphAwareDiffusion(LATENT_DIM, HIDDEN_DIM, DIFFUSION_STEPS, n_eigenvectors).to(device)\n",
    "\n",
    "n_vae_params = sum(p.numel() for p in vae.parameters())\n",
    "n_diff_params = sum(p.numel() for p in diffusion.parameters())\n",
    "\n",
    "print(f\"GraphVAE: {n_vae_params:,} parameters\")\n",
    "print(f\"GraphAwareDiffusion: {n_diff_params:,} parameters\")\n",
    "print(f\"Total: {n_vae_params + n_diff_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_vae = torch.optim.AdamW(vae.parameters(), lr=LEARNING_RATE)\n",
    "scheduler_vae = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_vae, AE_EPOCHS)\n",
    "\n",
    "vae_losses = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "print(f\"Training VAE for {AE_EPOCHS} epochs...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(AE_EPOCHS):\n",
    "    vae.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch_x, batch_params in dataloader:\n",
    "        optimizer_vae.zero_grad()\n",
    "        x_recon, mu, logvar, z = vae(batch_x, eigenvectors_tensor)\n",
    "        recon_loss = F.mse_loss(x_recon, batch_x)\n",
    "        kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        loss = recon_loss + 0.001 * kl_loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(vae.parameters(), 1.0)\n",
    "        optimizer_vae.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    scheduler_vae.step()\n",
    "    avg_loss = epoch_loss / len(dataloader)\n",
    "    vae_losses.append(avg_loss)\n",
    "\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(vae.state_dict(), f\"{OUTPUT_DIR}/vae_best.pt\")\n",
    "\n",
    "    if (epoch + 1) % 50 == 0 or epoch == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"  Epoch {epoch+1:3d}/{AE_EPOCHS} | Loss: {avg_loss:.6f} | {elapsed:.1f}s\")\n",
    "\n",
    "print(f\"VAE training complete. Best loss: {best_loss:.6f}\")\n",
    "vae.load_state_dict(torch.load(f\"{OUTPUT_DIR}/vae_best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot VAE training curve\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(vae_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VAE Training Loss')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Encode to Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    all_latents = vae.encode(solutions_tensor, eigenvectors_tensor)\n",
    "\n",
    "print(f\"Latent codes: {all_latents.shape}\")\n",
    "print(f\"Mean: {all_latents.mean().item():.4f}, Std: {all_latents.std().item():.4f}\")\n",
    "\n",
    "latent_dataset = TensorDataset(all_latents)\n",
    "latent_dataloader = DataLoader(latent_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize latent space with PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "latents_2d = pca.fit_transform(all_latents.cpu().numpy())\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "scatter = plt.scatter(latents_2d[:, 0], latents_2d[:, 1], \n",
    "                      c=parameters[:, 0], cmap='viridis', alpha=0.7)\n",
    "plt.colorbar(scatter, label='Diffusivity')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Latent Space (colored by diffusivity)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Train Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_diff = torch.optim.AdamW(diffusion.parameters(), lr=LEARNING_RATE)\n",
    "scheduler_diff = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_diff, DIFF_EPOCHS)\n",
    "\n",
    "diff_losses = []\n",
    "best_diff_loss = float('inf')\n",
    "\n",
    "print(f\"Training Diffusion for {DIFF_EPOCHS} epochs...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(DIFF_EPOCHS):\n",
    "    diffusion.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for (batch_z,) in latent_dataloader:\n",
    "        optimizer_diff.zero_grad()\n",
    "        t = torch.randint(0, DIFFUSION_STEPS, (batch_z.size(0),), device=device)\n",
    "        z_noisy, noise = diffusion.add_noise(batch_z, t)\n",
    "        noise_pred = diffusion(z_noisy, t)\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(diffusion.parameters(), 1.0)\n",
    "        optimizer_diff.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    scheduler_diff.step()\n",
    "    avg_loss = epoch_loss / len(latent_dataloader)\n",
    "    diff_losses.append(avg_loss)\n",
    "\n",
    "    if avg_loss < best_diff_loss:\n",
    "        best_diff_loss = avg_loss\n",
    "        torch.save(diffusion.state_dict(), f\"{OUTPUT_DIR}/diffusion_best.pt\")\n",
    "\n",
    "    if (epoch + 1) % 50 == 0 or epoch == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"  Epoch {epoch+1:3d}/{DIFF_EPOCHS} | Loss: {avg_loss:.6f} | {elapsed:.1f}s\")\n",
    "\n",
    "print(f\"Diffusion training complete. Best loss: {best_diff_loss:.6f}\")\n",
    "diffusion.load_state_dict(torch.load(f\"{OUTPUT_DIR}/diffusion_best.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot diffusion training curve\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(diff_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Diffusion Training Loss')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Generate Synthetic Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "diffusion.eval()\n",
    "\n",
    "N_SYNTHETIC = 16\n",
    "\n",
    "print(f\"Generating {N_SYNTHETIC} synthetic samples...\")\n",
    "with torch.no_grad():\n",
    "    synthetic_latents = diffusion.sample(N_SYNTHETIC, device)\n",
    "    synthetic_fields = vae.decode(synthetic_latents, eigenvectors_tensor)\n",
    "    synthetic_fields = synthetic_fields.cpu().numpy()\n",
    "\n",
    "print(f\"Generated fields shape: {synthetic_fields.shape}\")\n",
    "print(f\"Value range: [{synthetic_fields.min():.3f}, {synthetic_fields.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize synthetic samples\n",
    "fig, axes = plt.subplots(4, 4, figsize=(14, 12))\n",
    "fig.suptitle('Synthetic FEA Fields (Generated)', fontsize=14, fontweight='bold')\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    field = np.clip(synthetic_fields[i], 0, 1)\n",
    "    levels = np.linspace(0, 1, 25)\n",
    "    ax.tricontourf(triang, field, levels=levels, cmap='inferno', extend='both')\n",
    "    ax.tricontour(triang, field, levels=8, colors='white', linewidths=0.3, alpha=0.5)\n",
    "    circle = plt.Circle((0, 0), CYLINDER_RADIUS, fill=True, color='cyan', ec='black', lw=0.5)\n",
    "    ax.add_patch(circle)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'Sample {i+1}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Compare Real vs Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('Real vs Synthetic Comparison', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Top row: real samples\n",
    "for i in range(4):\n",
    "    ax = axes[0, i]\n",
    "    idx = np.random.randint(n_samples)\n",
    "    field = solutions[idx]\n",
    "    levels = np.linspace(0, 1, 25)\n",
    "    ax.tricontourf(triang, field, levels=levels, cmap='inferno', extend='both')\n",
    "    circle = plt.Circle((0, 0), CYLINDER_RADIUS, fill=True, color='cyan', ec='black', lw=0.5)\n",
    "    ax.add_patch(circle)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'Real {i+1}')\n",
    "    ax.axis('off')\n",
    "\n",
    "# Bottom row: synthetic samples\n",
    "for i in range(4):\n",
    "    ax = axes[1, i]\n",
    "    field = np.clip(synthetic_fields[i], 0, 1)\n",
    "    levels = np.linspace(0, 1, 25)\n",
    "    ax.tricontourf(triang, field, levels=levels, cmap='inferno', extend='both')\n",
    "    circle = plt.Circle((0, 0), CYLINDER_RADIUS, fill=True, color='cyan', ec='black', lw=0.5)\n",
    "    ax.add_patch(circle)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'Synthetic {i+1}')\n",
    "    ax.axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('REAL', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('SYNTHETIC', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent space visualization with synthetic samples\n",
    "synthetic_2d = pca.transform(synthetic_latents.cpu().numpy())\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(latents_2d[:, 0], latents_2d[:, 1], c='blue', alpha=0.5, s=20, label='Real')\n",
    "plt.scatter(synthetic_2d[:, 0], synthetic_2d[:, 1], c='red', alpha=0.8, s=100, marker='*', label='Synthetic')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Latent Space: Real vs Synthetic')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save synthetic samples\n",
    "np.savez(f\"{OUTPUT_DIR}/synthetic_samples.npz\",\n",
    "         fields=synthetic_fields,\n",
    "         latents=synthetic_latents.cpu().numpy())\n",
    "\n",
    "# Save final models\n",
    "torch.save({\n",
    "    'vae_state_dict': vae.state_dict(),\n",
    "    'diffusion_state_dict': diffusion.state_dict(),\n",
    "    'config': {\n",
    "        'latent_dim': LATENT_DIM,\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'n_encoder_layers': N_ENCODER_LAYERS,\n",
    "        'n_decoder_layers': N_DECODER_LAYERS,\n",
    "        'diffusion_steps': DIFFUSION_STEPS,\n",
    "        'n_nodes': n_nodes,\n",
    "        'n_eigenvectors': n_eigenvectors\n",
    "    }\n",
    "}, f\"{OUTPUT_DIR}/models_final.pt\")\n",
    "\n",
    "print(f\"Saved to {OUTPUT_DIR}/\")\n",
    "print(f\"  - synthetic_samples.npz\")\n",
    "print(f\"  - models_final.pt\")\n",
    "print(f\"  - vae_best.pt\")\n",
    "print(f\"  - diffusion_best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Generate More Samples (Interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_plot(n_samples=4):\n",
    "    \"\"\"Generate new synthetic samples on demand.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        z = diffusion.sample(n_samples, device)\n",
    "        fields = vae.decode(z, eigenvectors_tensor).cpu().numpy()\n",
    "    \n",
    "    cols = min(4, n_samples)\n",
    "    rows = (n_samples + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 3.5*rows))\n",
    "    if n_samples == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        ax = axes[i]\n",
    "        field = np.clip(fields[i], 0, 1)\n",
    "        ax.tricontourf(triang, field, levels=25, cmap='inferno')\n",
    "        circle = plt.Circle((0, 0), CYLINDER_RADIUS, fill=True, color='cyan', ec='black')\n",
    "        ax.add_patch(circle)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fields\n",
    "\n",
    "# Generate 4 new samples\n",
    "new_samples = generate_and_plot(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training complete!\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  - Dataset: {n_samples} FEA solutions, {n_nodes} nodes each\")\n",
    "print(f\"  - VAE final loss: {vae_losses[-1]:.6f}\")\n",
    "print(f\"  - Diffusion final loss: {diff_losses[-1]:.6f}\")\n",
    "print(f\"  - Model parameters: {n_vae_params + n_diff_params:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}